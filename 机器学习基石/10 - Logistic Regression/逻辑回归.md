> [机器学习基石下](https://www.coursera.org/learn/ntumlone-algorithmicfoundations) (Machine Learning Foundations)---Mathematical Foundations
> [Hsuan-Tien Lin, 林轩田](https://www.coursera.org/instructor/htlin)，副教授 (Associate Professor)，资讯工程学系 (Computer Science and Information Engineering)

# Logistic Regression

## Logistic Regression Problem

- logistic hypothesis: $h(\mathbf x)=\theta (\mathbf w^T \mathbf x)$ 

- logistic function $\theta (s)=\frac{1}{1+e^{-s}}$ 

- $sign(h(\mathbf x)-0.5)=sign(\mathbf w^T \mathbf x)$ 

## Logistic Regression Error

- Likelihood of Logistic Hypothesis

  ![Likelihood of Logistic Hypothesis](Likelihood of Logistic Hypothesis.png)

  极大似然

- cross-entropy error

  ![cross entropy error](cross entropy error.png)

  在极大似然估计下，logistic方程的误差函数

## Gradient of Logistic Regression Error

- Minimizing $E_{in}(\mathbf w)$ 

  ![minimizing Ein](minimizing Ein.png)

- PLA Revisited: Iterative Optimization

  ![iterative optimization](iterative optimization.png)

## Gradient Descent

- Linear Approximation

  ![Linear Approximatio](Linear Approximatio.png)

- Simple Heuristic for Changing $\eta$ 

  ![Simple Heuristic for Changing η](Simple Heuristic for Changing η.png)

- Logistic Regression Algorithm

  ![Logistic Regression Algorithm](Logistic Regression Algorithm.png)