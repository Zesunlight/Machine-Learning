> [机器学习基石下](https://www.coursera.org/learn/ntumlone-algorithmicfoundations) (Machine Learning Foundations)---Mathematical Foundations
> [Hsuan-Tien Lin, 林轩田](https://www.coursera.org/instructor/htlin)，副教授 (Associate Professor)，资讯工程学系 (Computer Science and Information Engineering)

# Hazard of Overfitting

## What is Overfitting?

- bad generalization: low $E_{in}$, high $E_{out}$ 

- example

  ![拟合例子](拟合例子.png)

- Cause of Overfitting

  - excessive $d_{VC}$ 
  - noise
  - limited data size

## The Role of Noise and Data Size

- concession for advantage

- Learning Curves Revisited

  ![Learning Curves Revisited](Learning Curves Revisited.png)

- ‘target complexity’ acts like noise

## Deterministic Noise

- A Detailed Experiment

  ![A Detailed Experiment](A Detailed Experiment.png)

- The Results

  ![The Results](The Results.png)

  - impact of $σ^2$ versus N: stochastic noise
  - impact of $Q_f$ versus N: deterministic noise

- four reasons of serious overfitting

  ![four reasons of serious overfitting](four reasons of serious overfitting.png)

  overfitting ‘easily’ happens

- Deterministic Noise

  ![Deterministic Noise](Deterministic Noise.png)

  pseudo-random generator 伪随机数发生器

## Dealing with Overfitting

Driving Analogy Revisited

![Driving Analogy Revisited](Driving Analogy Revisited.png)

- correct the label (data cleaning)
- remove the example (data pruning)
- add virtual examples by shifting/rotating the given digits (data hinting)

possibly helps, but effect varies (改变数据的分布)